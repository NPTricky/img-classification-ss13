\documentclass[liststotoc,11pt,a4paper]{article}

\usepackage[scaled=0.88]{beraserif}
\usepackage[scaled=0.85]{berasans}
\usepackage[scaled=0.84]{beramono}

\usepackage{mathtext}
\usepackage[T1]{fontenc}            
\usepackage[utf8]{inputenc}
\usepackage[english,ngerman]{babel}
\usepackage{amsmath,amssymb,amsthm}
\usepackage{mathtools}
\usepackage{isomath}

\usepackage{mathpazo}
\linespread{1.05}
\usepackage[T1,small,euler-digits]{eulervm}

\usepackage{layouts}
\usepackage[pdftex]{graphicx}

\usepackage[
twoside, % zweiseitiger Druck
left=2.5cm, % linker Rand
right=2.5cm, % rechter Rand
top=1.5cm, % oberer Rand
bottom=2.5cm, % unterer Rand
]{geometry}
\usepackage[printonlyused]{acronym} %Abkürzungen
\usepackage{float}
\usepackage{capt-of}

\begin{document}
% ------------------------------------------------- Deckblatt -------------------------------------------------------------
\begin{figure}[htbp]
\begin{minipage}[t]{5cm}
\vspace{0pt}
\includegraphics{ovgu_logo_fak_inf}
\end{minipage}
\hfill
\begin{minipage}[t]{8cm}
\vspace{0pt}
\begin{flushright}     
Otto-von-Guericke-Universität Magdeburg\\Fakultät für Informatik\\AG Bildverarbeitung und Bildverstehen\\
\end{flushright}
\end{minipage}
\end{figure}
\vspace{50pt}

\begin{center}
\huge\bfseries Report zu Projekt Samael\\
\vspace{10pt}
\large"`The Blind God"'\\
\end{center}
\begin{center}
\vspace{20pt}
------------------------------------------------------------------------------------------------------------------\\[30pt]
\large Klassifikation von Bildern\\
\vspace{10pt}
\normalsize 10.07.2013 \\[220pt] 
\end {center}

\begin{figure}[htbp]
\begin{minipage}[t]{4.5cm}
\begin{flushleft}
Tim Benedict Jagla \\
Computervisualistik\\
Matrikelnr.: 187768\\ 
tim.jagla@st.ovgu.de\\
\end{flushleft}
\end{minipage}
\begin{minipage}[t]{4.8cm}
\begin{flushleft}
Christoph Lämmerhirt\\
Informatik\\
Matrikelnr.: 187685\\
christoph.laemmerhirt@st.ovgu.de\\
\end{flushleft}
\end{minipage}
\hfill
\begin{minipage}[t]{4.5cm}
\begin{flushleft} 
Sarah Pauksch\\
Computervisualistik\\
Matrikelnr: 188145\\ 
sarah.pauksch@st.ovgu.de\\
\end{flushleft}
\end{minipage}
\end{figure}

\vspace{\fill}

\begin{figure}[htbp]
\begin{minipage}[b]{0.475\textwidth}
\vspace{0pt}
\begin{flushright}    
\begin {tabbing}
\hspace*{5cm}\=\hspace{2,5cm}\=\hspace{5cm}\=\hspace{2.5cm}\=\hspace{2.5cm}\=\kill
Professor:	\>Prof. Dr.-Ing. Klaus Tönnies\\
Kurs: \>Advanced Topics in Image Understanding\\

\end{tabbing}
\end{flushright}
\end{minipage}
\hfill
\begin{minipage}[b]{0.475\textwidth}
\centering
\end{minipage}
\end{figure}


\thispagestyle{empty}
\newpage
%-----------------------------------------Verzeichnisse-----------------------------------------------------------------
%------------------------------                                   ------------------------------------------------------
\tableofcontents                % automatisches Inhaltsverzeichnis
\pagenumbering{Roman}
\newpage
\setcounter{page}{1}
\pagenumbering{arabic}
%------------------------------------------------ eigentlicher Text -----------------------------------------------------

\Large \bfseries Abstrakt\\
\normalsize \mdseries
\addcontentsline{toc}{section}{Abstrakt}
\normalfont
\\Im Rahmen von Projekt Samael wurde sich mit der Klassifizierung von Bildern auseinander gesetzt. Das Ziel der Arbeit ist es, mehrere tausend Bilder einzulesen, zu verarbeiten und als Ergebnis eine korrekte Einteilung in verschiedene Klassen zu erhalten. Für die Umsetzung wurde mit Visual Studio 2010 bzw. 2012 in Verbindung mit den Bibliotheken Qt 5.0.1 und OpenCV 2.4.5 gearbeitet. In dem entwickelten Verfahren kommen Methoden wie zum Beispiel 'Bag of Words', 'SIFT' und 'Support Vector Machine' zum Einsatz. %vielleicht schon genauer?
Grundlage für die Evaluierung der Arbeit ist der Datensatz der Caltech101. 

\section{Einleitung}
In dem Kurs 'Advanced Topics in Image Understanding' an der Universität Magdeburg stand im Sommersemester 2013 das Thema der Bildklassifikation im Mittelpunkt. Dazu gab es ein studentisches Projekt, in dem Bilder verschiedener Objekte gruppiert werden sollten. Dazu haben sich aufgeteilte Teams mit dem nicht-trivialen Analyseproblem beschäftigt. Die Aufgabe bestand darin, die Bilder eines vorgegebenen Datensatzes mit mindestens zehnprozentiger Korrektheit zu klassifizieren. 
Um das zu erreichen, muss ein sinnvoller feature-Descriptor und eine geeignete Klassifikationsmethode ausgewählt und implementiert werden. 50 Prozent des Datensatzes soll für das Training des Klassifizierers genutzt werden.

\section{Verfahren}
Für die Umsetzung wurde ein Algorithmus mit Visual Studio 2010 bzw. 2012 in Verbindung mit den Bibliotheken Qt 5.0.1 und OpenCV 2.4.5 implementiert. Qt eignet sich gut für die Erstellung eines User Interface und OpenCV bietet viele hilfreiche Funktionen für die Bildverarbeitung.\\Um die Bedienung zu erleichtern, wurde eine Bedienoberfläche, wie in Abbildung 1 zu sehen, erstellt.

% Abbildung 1 User Interface

Auf der linken Seite können die Bilder über einen Filebrowser geladen werden. Die mittlere Anzeige bringt Aufschluss darüber, wie die Bilder nach Start der Klassifizierung aufgeteilt wurden. Rechts besteht die Möglichkeit zwischen drei Keypoint Detektoren zu wählen, um anschließend den Verarbeitungsprozess zu starten. % to do: besser, mehr ?

\subsection{Algorithmus}

Die folgende Abbildung zeigt den Aufbau des Verfahrens zur Lösung des Klassifizierungsproblems.

% bild pipeline --> tim

Nachdem die Bilder über das User Interface eingeladen wurden, müssen zuerst die Features extrahiert werden. Dafür werden für jedes Bild Keypoints detektiert, die widerum für Descriptoren stehen. Der User bekommt zur Auswahl, welche der Methoden SIFT, SURF oder MSER angewendet werden soll. Dadurch konnten Vergleiche zwischen den verschiedenen Verfahren aufgestellt werden. SIFT wurde gewählt, da es ein sehr robustes Verfahren ist. Zum Vergleich wurde SURF genutzt, um Unterschiede zu der langsameren Methode zu finden. MSER ist noch einfacher und schneller als SIFT und SURF und ebenfalls interessant bei der Ergebnisuntersuchung. (Mehrere Informationen dazu in Abschnitt 'Evaluation')
\\Sobald die Features berechnet sind, geht es an das Clustering. Die maximal 101 Cluster samt Clusterzentren werden in einem Wörterbuch gespeichert, welches von der Bag-of-Words - Klasse in OpenCV gesteuert wird. Für jedes Bild wird der SVM (Support Vector Machine) mit den berechneten Daten trainiert. Dazu bekommt er ein Histogramm über die Clusterzentren. Als Grundlage für das Verfahren wurde ein Paper von Gabriella Csurka, Christopher R. Dance, Lixin Fan, Jutta Willamowski und Cédric Bray %et al. ?
gelesen. \cite{pizza} Darin werden verschiedene Möglichkeiten beschrieben Fotos zu klassifizieren. Dabei wird auf den Bag-of-Words Algorithmus eingegangen. Außerdem wird der SVM mit dem naiven Bayes-Klassifizierer verglichen, wobei SVM die Fehlerrate gegenüber Bayes enorm senkt.
\\Für die Klassifizierung durchläuft das Bild die gleiche Pipeline wie die Trainingsdaten. Anschließend wird das Response aller SVMs betrachtet. Dabei gilt das Prinzip 1-versus-all, das bedeutet, dass das aktuelle Bild allen trainierten Datensätzen gegenüber gestellt wird. Somit wird herausgefunden, welches das nächstliegende Cluster im Wörterbuch und somit die zugehörige Klasse ist.

%•Decision on features (justification, the measure itself)
%•Classification details

\subsection{Probleme}
Alles in Allem, war dieses Projekt frei von größeren Problemen. Trotzdem funktionierte nicht alles perfekt. Eine Schwierigkeit war die lange Rechenzeit. Ein Durchlauf mit 20 Testläufen benötigte rund 48 Stunden.%todo genaue Zahl von Tim
Dadurch wurde im Projekt auf größere Optimierungen, wie zum Beispiel eine Principal Component Analyse, verzichtet. Ebenso wurde der Testlauf mit nur einem der drei zur Wahl stehenden Algorithmen komplett durchgeführt. Die Entscheidung viel auf das SIFT-Verfahren, da dabei die beste Keypointdetektion stattfand. (Zum Vergleich, SURF hat die dreifache Anzahl an Keypoints geliefert.) MSER und SURF wurden nur in kleinere Tests für den Vergleich einbezogen. 
\\Außerdem gab es Probleme mit OpenGL. Die Idee war verschiedene multivariate Daten, wie zum Beispiel Descriptoren oder Histogramme, als Koordinatenvisualisierungen darzustellen, um Schwachstellen des Verfahrens leicht zu erkennen. Das stellte sich jedoch als zu komplex für den Zeitrahmen der Lehrveranstaltung heraus und deshalb wurde darauf verzichtet.
\\Zuletzt sind noch Beschränkungen durch Qt 5.0.1 zu erwähnen. Zum Einen gab es Performanceprobleme sobald die Bilder über ein Directory geladen wurden. Zum Anderen wird derzeit OpenGL in Qt neu aufgesetzt, wodurch es zu Problemen beim üblichen OpenGL gab. Qt war inkompatibel zu der Bibliothek.

\section{Evaluierung}
Für die Validierung des Programmes wurden die xxx %todo
Bilder des vorgegebenen Datensatzes Caltech101 eingelesen. Dabei handelt es sich um eine Referenz, für das Testen von Bildklassifikationsmethoden. Alle Bilder haben die gleiche Größe von 300x200 Pixel, zeigen ein Objekt zentriert und sind Fotos, Zeichnungen oder Skizzen. Alle Eingabebilder sind in 101 verschiedene Klassen einzuteilen. Jede einzelne Klasse behinhaltet 30 bis 80 Sampelbilder. 
50 Prozent des Datensatzes sollen für das Training des Klassifizierers genutzt werden, der Rest für die Evaluierung. Das Verfahren wird 20-mal mit einer zufälligen Einteilung in Trainings- und Testdaten wiederholt.
Diese Testreihe wurde, aus bereits oben erwähnten Gründen, mit dem SIFT-Verfahren durchgeführt.

 
%•How the classifier was trained
%–Training details
%–Results (i.e. how good on training data, hints for subgroups, validity of features,…)
%•Tests on independent test data
%–Description of the test scenario
%–Results and any conclusions from that


\section{Zusammenfassung}
%•Conclusions (how would you rate your approach)
Zusammenfassend ist zu sagen, dass die erreichten Ergebnisse zufriedenstellend sind und die Anforderungen erfüllen. Es gibt jedoch noch Raum für Optimierungen. Threading könnte die Performance verbessern und die gesamte Anwendung beschleunigen. Dadurch könnte man wiederum die Principal Component Analyse oder die Independent Component Analyse einbauen. 
Wird zusätzlich OpenGL eingebunden, kann einfach ausgewertet werden, welche Klassen woran scheitern und zum Ausgleich könnten weitere Features eingebaut werden.
\\Die hohe Rate der korrekt klassifizierten Bilder ist erstaunlich, wenn bedacht wird, dass lediglich SIFT als Feature-Detektor eingesetzt wurde.



%------------------------------Literaturverzeichnis-----------------------------------------------------------------------
\newpage
\pagenumbering{Roman}
\setcounter{page}{3}
\renewcommand{\refname}{Referenzen}
\bibliographystyle{gerplain}
\addcontentsline{toc}{section}{Referenzen}
\bibliography{referenzen} %notwendig?


\end{document}