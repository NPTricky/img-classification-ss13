\documentclass[liststotoc,11pt,a4paper]{article}

\usepackage[scaled=0.88]{beraserif}
\usepackage[scaled=0.85]{berasans}
\usepackage[scaled=0.84]{beramono}

\usepackage{mathtext}
\usepackage[T1]{fontenc}            
\usepackage[utf8]{inputenc}
\usepackage[english,ngerman]{babel}
\usepackage{amsmath,amssymb,amsthm}
\usepackage{mathtools}
\usepackage{isomath}

\usepackage{mathpazo}
\linespread{1.05}
\usepackage[T1,small,euler-digits]{eulervm}

\usepackage{layouts}
\usepackage[pdftex]{graphicx}

\usepackage[
twoside, % zweiseitiger Druck
left=2.5cm, % linker Rand
right=2.5cm, % rechter Rand
top=1.5cm, % oberer Rand
bottom=2.5cm, % unterer Rand
]{geometry}
\usepackage[printonlyused]{acronym} %Abkürzungen
\usepackage{float}
\usepackage{capt-of}

\begin{document}
% ------------------------------------------------- Deckblatt -------------------------------------------------------------
\begin{figure}[htbp]
\begin{minipage}[t]{5cm}
\vspace{0pt}
\includegraphics{ovgu_logo_fak_inf}
\end{minipage}
\hfill
\begin{minipage}[t]{8cm}
\vspace{0pt}
\begin{flushright}     
Otto-von-Guericke-Universität Magdeburg\\Fakultät für Informatik\\AG Bildverarbeitung und Bildverstehen\\
\end{flushright}
\end{minipage}
\end{figure}
\vspace{50pt}

\begin{center}
\huge\bfseries Report zu Projekt Samael\\
\vspace{10pt}
\large"`The Blind God"'\\
\end{center}
\begin{center}
\vspace{20pt}
------------------------------------------------------------------------------------------------------------------\\[30pt]
\large Klassifikation von Bildern\\
\vspace{10pt}
\normalsize 10.07.2013 \\[220pt] 
\end {center}

\begin{figure}[htbp]
\begin{minipage}[t]{4.5cm}
\begin{flushleft}
Tim Benedict Jagla \\
Computervisualistik\\
Matrikelnr.: 187768\\ 
tim.jagla@st.ovgu.de\\
\end{flushleft}
\end{minipage}
\begin{minipage}[t]{4.8cm}
\begin{flushleft}
Christoph Lämmerhirt\\
Informatik\\
Matrikelnr.: 187685\\
christoph.laemmerhirt@st.ovgu.de\\
\end{flushleft}
\end{minipage}
\hfill
\begin{minipage}[t]{4.5cm}
\begin{flushleft} 
Sarah Pauksch\\
Computervisualistik\\
Matrikelnr: 188145\\ 
sarah.pauksch@st.ovgu.de\\
\end{flushleft}
\end{minipage}
\end{figure}

\vspace{\fill}

\begin{figure}[htbp]
\begin{minipage}[b]{0.475\textwidth}
\vspace{0pt}
\begin{flushright}    
\begin {tabbing}
\hspace*{5cm}\=\hspace{2,5cm}\=\hspace{5cm}\=\hspace{2.5cm}\=\hspace{2.5cm}\=\kill
Professor:	\>Prof. Dr.-Ing. Klaus Tönnies\\
Kurs: \>Advanced Topics in Image Understanding\\

\end{tabbing}
\end{flushright}
\end{minipage}
\hfill
\begin{minipage}[b]{0.475\textwidth}
\centering
\end{minipage}
\end{figure}


\thispagestyle{empty}
\newpage
%-----------------------------------------Verzeichnisse-----------------------------------------------------------------
%------------------------------                                   ------------------------------------------------------
\tableofcontents                % automatisches Inhaltsverzeichnis
\pagenumbering{Roman}
\setcounter{page}{1}
\pagenumbering{arabic}
\newpage
%------------------------------------------------ eigentlicher Text -----------------------------------------------------

\Large \bfseries Abstrakt\\
\normalsize \mdseries
\addcontentsline{toc}{section}{Abstrakt}
\normalfont
\\Im Rahmen von Projekt Samael wurde sich mit der Klassifizierung von Bildern auseinander gesetzt. Das Ziel der Arbeit ist es, mehrere tausend Bilder einzulesen, zu verarbeiten und als Ergebnis eine korrekte Einteilung in verschiedene Klassen zu erhalten. Für die Umsetzung wurde mit Visual Studio 2010 bzw. 2012 in Verbindung mit den Bibliotheken Qt 5.0.1 und OpenCV 2.4.5 gearbeitet. In dem entwickelten Verfahren kommen Methoden wie zum Beispiel 'Bag of Words', 'SIFT' und 'Support Vector Machine' zum Einsatz. %vielleicht schon genauer?
Grundlage für die Evaluierung der Arbeit ist der Datensatz der Caltech101. 

\section{Einleitung}
In dem Kurs 'Advanced Topics in Image Understanding' an der Universität Magdeburg stand im Sommersemester 2013 das Thema der Bildklassifikation im Mittelpunkt. Dazu gab es ein studentisches Projekt, in dem Bilder verschiedener Objekte gruppiert werden sollten. Dazu haben sich aufgeteilte Teams mit dem nicht-trivialen Analyseproblem beschäftigt. Die Aufgabe bestand darin, die Bilder eines vorgegebenen Datensatzes mit mindestens zehnprozentiger Korrektheit zu klassifizieren. 
Um das zu erreichen, muss ein sinnvoller feature-Descriptor und eine geeignete Klassifikationsmethode ausgewählt und implementiert werden. 50 Prozent des Datensatzes soll für das Training des Klassifizierers genutzt werden.

\section{Verfahren}
Für die Umsetzung wurde ein Algorithmus mit Visual Studio 2010 bzw. 2012 in Verbindung mit den Bibliotheken Qt 5.0.1 und OpenCV 2.4.5 implementiert. Qt eignet sich gut für die Erstellung eines User Interface und OpenCV bietet viele hilfreiche Funktionen für die Bildverarbeitung.\\Um die Bedienung zu erleichtern, wurde eine Bedienoberfläche, wie in Abbildung 1 zu sehen, erstellt.

% Abbildung 1 User Interface

Auf der linken Seite können die Bilder über einen Filebrowser geladen werden. Die mittlere Anzeige bringt Aufschluss darüber, wie die Bilder nach Start der Klassifizierung aufgeteilt wurden. Rechts besteht die Möglichkeit zwischen drei Keypoint Detektoren zu wählen, um anschließend den Verarbeitungsprozess zu starten. % to do: besser, mehr ?

\subsection{Algorithmus}

Die folgende Abbildung zeigt den Aufbau des Verfahrens zur Lösung des Klassifizierungsproblems.

% bild pipeline --> tim

Nachdem die Bilder über das User Interface eingeladen wurden, müssen zuerst die Features extrahiert werden. Dafür werden für jedes Bild Keypoints detektiert, die widerum für Descriptoren stehen. Der User bekommt zur Auswahl, ob die Methode von SIFT, SURF oder MSER angewendet werden soll. Dadurch konnten Vergleiche zwischen den verschiedenen Verfahren aufgestellt werden. (Mehrere Informationen dazu in Abschnitt 'Evaluation')
Sobald die Features berechnet sind, geht es an das Clustering. Die Cluster samt Clusterzentren werden in einem Wörterbuch gespeichert, welches von der Bag-of-Words - Klasse in OpenCV gesteuert wird. Für jedes Bild wird der SVM (Support Vector Machine) mit den berechneten Daten trainiert. Dazu bekommt er ein Histogramm über die Clusterzentren. Für die Klassifizierung durchläuft das Bild die gleiche Pipeline wie die Trainingsdaten. Anschließend wird das Response aller SVMs betrachtet. Dabei gilt das Prinzip 1-versus-all, das bedeutet, dass das aktuelle Bild allen anderen Datensätzen gegenüber gestellt wird. Somit wird herausgefunden, welches das nächstliegende Cluster im Wörterbuch ist.


vorteile der algos raussuchen


%•Decision on features (justification, the measure itself)
%•Classification details

\subsection{Probleme}
Alles in Allem, war dieses Projekt frei von größeren Problemen. Trotzdem funktionierte nicht alles perfekt. Eine Schwierigkeit war die lange Rechenzeit. Ein Durchlauf mit 20 Testläufen benötigte rund 48 Stunden.%todo genaue Zahl von Tim
Dadurch wurde im Projekt auf größere Optimierungen, wie zum Beispiel eine Principal Component Analyse, verzichtet. Ebenso wurde der Testlauf mit nur einem der drei zur Wahl stehenden Algorithmen komplett durchgeführt. Die Entscheidung viel auf das SIFT-Verfahren, da dabei die beste Keypointdetektion stattfand. (Zum Vergleich, SURF hat die dreifache Anzahl an Keypoints geliefert.) MSER und SURF wurden nur in kleinere Tests zum Vergleich einbezogen. 
\\Außerdem gab es Probleme mit OpenGL. Die Idee war verschiedene multivariate Daten, wie zum Beispiel Descriptoren oder Histogramme, als Koordinatenvisualisierungen darzustellen. Das stellte sich jedoch als zu komplex für den Zeitrahmen der Lehrveranstaltung heraus und deshalb wurde darauf verzichtet.
Zuletzt sind noch Beschränkungen durch Qt 5.0.1 zu erwähnen. Zum Einen gab es Performanceprobleme sobald die Bilder über ein Directory geladen wurden. Zum Anderen wird derzeit OpenGL in Qt neu aufgesetzt, wodurch es zu Problemen beim üblichen OpenGL gab. Qt war inkompatibel zu der Bibliothek.

\section{Evaluierung}
Für die Validierung des Programmes wurden die xxx Bilder des vorgegebenen Datensatzes Caltech101 eingelesen. Dabei handelt es sich um eine Referenz, für das Testen von Bildklassifikationsmethoden. Alle Bilder haben die gleiche Größe von 300x200 Pixel, zeigen ein Objekt zentriert und sind Fotos, Zeichnungen oder Skizzen. Alle Eingabebilder sind in 101 verschiedene Klassen einzuteilen. Jede einzelne Klasse behinhaltet 30 bis 80 Samplebilder. 
50 Prozent des Datensatzes soll für das Training des Klassifizierers genutzt werden. Das Verfahren wird 20-mal mit einer zufälligen Einteilung in Trainings- und Testdaten wiederholt.


%Tabelle mit Vergleichwerten??? zB zwischen SIFT/SURF/MSER 


%•How the classifier was trained
%–Training details
%–Results (i.e. how good on training data, hints for subgroups, validity of features,…)
%•Tests on independent test data
%–Description of the test scenario
%–Results and any conclusions from that


\section{Zusammenfassung}
%•Conclusions (how would you rate your approach)
Zusammenfassend ist zu sagen, dass die erreichten Ergebnisse die Anforderungen erfüllen. Es gibt jedoch noch viel Raum für Optimierungen. Threading könnte die Performance verbessern und die gesamte Anwendung beschleunigen. Dadurch könnte man wiederum die Principal Component Analyse oder die Independent Component Analyse. 
Wird zusätzlich OpenGL eingebunden, kann einfach ausgewertet werden, welche Klassen woran scheitern und zum Ausgleich könnten andere Features eingebaut werden.
Als Hilfe wurde ein Paper von Gabriella Csurka, Christopher R. Dance, Lixin Fan, Jutta Willamowski und Cédric Bray gelesen.\cite{pizza}
Als Fazit lässt sich sagen, dass es erstaunlich ist, mit welch hoher Korrektheit Bilder klassifiziert werden können, mithilfe nur weniger Algoithmen.


%------------------------------Literaturverzeichnis-----------------------------------------------------------------------
\newpage
\pagenumbering{Roman}
\setcounter{page}{3}
\renewcommand{\refname}{Referenzen}
\bibliographystyle{gerplain}
\addcontentsline{toc}{section}{Referenzen}
\bibliography{referenzen} %notwendig?


\end{document}